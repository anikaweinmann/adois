import logging
import os
from datetime import datetime as DateTime  # PEP8 compliant
from pathlib import Path

import enlighten
import geopandas as gpd

import src.utils as utils
from src.aggregation import Aggregator
from src.data import RemoteSensingDataDownloader, RemoteSensingLocalData
from src.inference import Inference
from src.postprocessing import Postprocessor
from src.preprocessing import Preprocessor
from src.utils import (ConfigParser, Coordinator, create_dir_structure, create_cached_tiles_dir, export,
                       get_argument_parser, get_metadata, GridGenerator)


def main():
    # region Argument parsing
    manager = enlighten.get_manager()
    status_bar = manager.status_bar(status_format=u'adois{fill}Stage: {stage}{fill}{elapsed}',
                                    justify=enlighten.Justify.CENTER,
                                    autorefresh=True,
                                    stage='Initializing')

    start_time = DateTime.now()

    argument_parser = get_argument_parser()
    args = argument_parser.parse_args()
    # endregion

    # region Config parsing
    config_parser = ConfigParser(args)
    config = config_parser.parse_config()
    # endregion

    # region Logging
    utils.DEBUG = args.debug

    logger_formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s: %(message)s',
                                         datefmt="%Y-%m-%d %H:%M:%S")
    logger = logging.getLogger('main_logger')

    console_handler = logging.StreamHandler()
    if utils.DEBUG:
        console_handler.setLevel(logging.DEBUG)
    else:
        console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logger_formatter)
    logger.addHandler(console_handler)

    if utils.DEBUG:
        date_time = str(DateTime.now().isoformat(sep='_', timespec='seconds')).replace(':', '-')
        file_handler = logging.FileHandler(Path(config.export_settings.output_dir_path) / f"{date_time}.log", mode='w')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(logger_formatter)
        logger.addHandler(file_handler)

    logger.setLevel(logging.DEBUG)

    utils.set_exception_hook()
    # endregion

    # region Initializing
    create_cached_tiles_dir(output_dir_path=config.export_settings.output_dir_path)
    logger.debug('cached_tiles directory created')

    coordinator = Coordinator()
    logger.debug('Coordinator initialized')

    if config.data.boundary_shape_file_path:
        boundary_gdf = gpd.read_file(config.data.boundary_shape_file_path)
        if boundary_gdf.crs is None:
            boundary_gdf = boundary_gdf.set_crs(f'EPSG:{config.data.epsg_code}')
        else:
            boundary_gdf = boundary_gdf.to_crs(f'EPSG:{config.data.epsg_code}')
        boundary_gdf = boundary_gdf[['geometry']]
        # noinspection PyTypeChecker
        coordinates = coordinator.get_valid_coordinates(bounding_box=config.data.bounding_box,
                                                        epsg_code=config.data.epsg_code,
                                                        boundary_gdf=boundary_gdf)
    else:
        boundary_gdf = None
        # noinspection PyTypeChecker
        coordinates = coordinator.get_coordinates(bounding_box=config.data.bounding_box)
    logger.debug('Coordinates calculated')

    if not config.data.ignore_cached_tiles:
        filtered_coordinates = \
            coordinator.filter_cached_coordinates(coordinates=coordinates,
                                                  output_dir_path=config.export_settings.output_dir_path)
        logger.debug('Coordinates filtered')
    else:
        filtered_coordinates = coordinates

    preprocessor = Preprocessor()
    logger.debug('Preprocessor initialized')

    resolution = None
    if hasattr(config.data, "dop_dir"):
        # use local data
        rsdd_rgbi = RemoteSensingLocalData(
            config.data.dop_dir,
            epsg_code=config.data.epsg_code,
            clip_border=config.data.clip_border,
        )
        resolution = config.data.resolution
        logger.debug('RemoteSensingLocalData (rgbi) initialized')
    else:
        # download data
        rsdd_rgb = RemoteSensingDataDownloader(wms_url=config.data.rgb.wms_url,
                                            wms_layer=config.data.rgb.wms_layer,
                                            epsg_code=config.data.epsg_code,
                                            clip_border=config.data.clip_border)
        logger.debug('RemoteSensingDataDownloader (rgb) initialized')

        rsdd_nir = RemoteSensingDataDownloader(wms_url=config.data.nir.wms_url,
                                            wms_layer=config.data.nir.wms_layer,
                                            epsg_code=config.data.epsg_code,
                                            clip_border=config.data.clip_border)
        logger.debug('RemoteSensingDataDownloader (nir) initialized')

    inference = Inference(model_path='data/model/model.onnx',
                          clip_border=config.data.clip_border)
    logger.debug('Inference initialized')

    # noinspection PyTypeChecker
    postprocessor = Postprocessor(output_dir_path=config.export_settings.output_dir_path,
                                  bounding_box=config.data.bounding_box,
                                  epsg_code=config.data.epsg_code,
                                  boundary_gdf=boundary_gdf)
    logger.debug('Postprocessor initialized')

    # noinspection PyTypeChecker
    grid_generator = GridGenerator(bounding_box=config.data.bounding_box,
                                   epsg_code=config.data.epsg_code)
    logger.debug('GridGenerator initialized')

    iterations = len(filtered_coordinates)
    if iterations:
        logger.info(f'Iterations: {iterations}')
    else:
        logger.info('Iterations: 0 (area is already being processed)')
    # endregion

    # region Download
    # noinspection PyTypeChecker
    status_bar.update(stage='Download, Inference, Caching',
                      force=True)
    progress_bar = manager.counter(total=iterations,
                                   desc='Download, Inference, Caching',
                                   unit='tiles',
                                   count=0,
                                   min_delta=0)
    progress_bar.refresh()

    if hasattr(config.data, "dop_dir"):
        # load local data
        rgbi_files = [x for x in os.listdir(config.data.dop_dir) if x.endswith(config.data.dop_extension)]
        coordinates = []
        for index, rgbi_file in enumerate(rgbi_files):
            rgbi_image = rsdd_rgbi.get_image(rgbi_file)
            coordinates_element = rsdd_rgbi.get_top_left_coordinate(rgbi_file)
            coordinates.append(coordinates_element)
            logger.debug(f'Iteration {index + 1} / {iterations} ->  rgbi image loaded')

            image = rgbi_image / 255.
            mask = inference.get_mask(image)
            # numpy.ndarray
            logger.debug(f'Iteration {index + 1} / {iterations} -> mask created')

            postprocessor.vectorize_mask(
                mask=mask,
                coordinates=coordinates_element,
                res=resolution,
            )
            logger.debug(f'Iteration {index + 1} / {iterations} -> mask vectorized and cached')
            logger.info(f'Iteration {index + 1} / {iterations} -> tile cached')
            progress_bar.update()
    else:
        for index, coordinates_element in enumerate(filtered_coordinates):
            rgb_image = rsdd_rgb.get_image(coordinates_element)
            logger.debug(f'Iteration {index + 1} / {iterations} ->  rgb image downloaded')
            nir_image = rsdd_nir.get_image(coordinates_element)
            logger.debug(f'Iteration {index + 1} / {iterations} ->  nir image downloaded')

            image = preprocessor.get_image(rgb_image=rgb_image,
                                        nir_image=nir_image)

            mask = inference.get_mask(image)
            logger.debug(f'Iteration {index + 1} / {iterations} -> mask created')

            postprocessor.vectorize_mask(mask=mask,
                                        coordinates=coordinates_element)
            logger.debug(f'Iteration {index + 1} / {iterations} -> mask vectorized and cached')
            logger.info(f'Iteration {index + 1} / {iterations} -> tile cached')
            progress_bar.update()
    # endregion

    # region Postprocessing
    # noinspection PyTypeChecker
    status_bar.update(stage='Postprocessing',
                      force=True)
    raw_gdf = postprocessor.concatenate_gdfs(coordinates=coordinates)
    logger.info('Cached geodataframes concatenated')

    if config.postprocessing.sieve_size:
        postprocessed_gdf = postprocessor.sieve_gdf(raw_gdf,
                                                    sieve_size=config.postprocessing.sieve_size)
        postprocessed_gdf = postprocessor.fill_gdf(postprocessed_gdf,
                                                   hole_size=config.postprocessing.sieve_size)
        logger.info('Geodataframe postprocessed (sieved and filled)')
    else:
        postprocessed_gdf = None

    if config.postprocessing.simplify:
        if postprocessed_gdf is not None:
            postprocessed_gdf = postprocessor.simplify_gdf(postprocessed_gdf, res=resolution)
        else:
            postprocessed_gdf = postprocessor.simplify_gdf(raw_gdf, res=resolution)
        logger.info('Geodataframe postprocessed (simplified)')
    # endregion

    # region Create grids
    if config.aggregation.tile_size or config.aggregation.shape_file_path:
        # noinspection PyTypeChecker
        status_bar.update(stage='Aggregation',
                          force=True)

    gdfs_grid = []
    grid_iterations = len(config.aggregation.tile_size)

    for index, tile_size_meters in enumerate(config.aggregation.tile_size):
        gdfs_grid.append(grid_generator.get_grid(tile_size_meters=tile_size_meters))
        logger.info(f'Grid {index + 1} / {grid_iterations} created')
    # endregion

    # region Create Shape files
    gdfs_shape_file = []
    shape_file_iterations = len(config.aggregation.shape_file_path)

    for index, shape_file_path_element in enumerate(config.aggregation.shape_file_path):
        gdf = gpd.read_file(shape_file_path_element)
        if gdf.crs is None:
            gdf = gdf.set_crs(f'EPSG:{config.data.epsg_code}')
        else:
            gdf = gdf.to_crs(f'EPSG:{config.data.epsg_code}')
        gdfs_shape_file.append(gdf)
        logger.info(f'Shape file {index + 1} / {shape_file_iterations} created')
    # endregion

    # region Aggregation
    if postprocessed_gdf is None:
        # noinspection PyTypeChecker
        aggregator = Aggregator(gdf=raw_gdf,
                                bounding_box=config.data.bounding_box)
    else:
        # noinspection PyTypeChecker
        aggregator = Aggregator(gdf=postprocessed_gdf,
                                bounding_box=config.data.bounding_box)
    logger.debug('Aggregator initialized')

    aggregation_gdfs_grid = []

    for index, gdf_grid in enumerate(gdfs_grid):
        aggregation_gdfs_grid.append(aggregator.aggregate_gdf(aggregation_gdf=gdf_grid,
                                                              boundary_gdf=boundary_gdf))
        logger.info(f'Grid {index + 1} / {grid_iterations} aggregated')

    aggregation_gdfs_shape_file = []

    for index, gdf_shape_file in enumerate(gdfs_shape_file):
        aggregation_gdfs_shape_file.append(aggregator.aggregate_gdf(aggregation_gdf=gdf_shape_file,
                                                                    boundary_gdf=boundary_gdf))
        logger.info(f'Shape file {index + 1} / {shape_file_iterations} aggregated')
    # endregion

    # region Export
    end_time = DateTime.now()

    # noinspection PyTypeChecker
    status_bar.update(stage='Export',
                      force=True)

    create_dir_structure(output_dir_path=config.export_settings.output_dir_path,
                         export_raw_shape_file=config.export_settings.export_raw_shape_file,
                         tile_sizes=config.aggregation.tile_size,
                         shape_file_paths=config.aggregation.shape_file_path)
    logger.debug('Directory structure in output directory created')

    metadata = get_metadata(config=config_parser.config_dict,
                            start_time=start_time,
                            end_time=end_time)
    logger.debug('Metadata created')

    export(output_dir_path=config.export_settings.output_dir_path,
           export_raw_shape_file=config.export_settings.export_raw_shape_file,
           raw_gdf=raw_gdf,
           postprocessed_gdf=postprocessed_gdf,
           prefix=config.export_settings.prefix,
           tile_sizes=config.aggregation.tile_size,
           aggregation_gdfs_grid=aggregation_gdfs_grid,
           shape_file_paths=config.aggregation.shape_file_path,
           aggregation_gdfs_shape_file=aggregation_gdfs_shape_file,
           metadata=metadata)
    logger.info('Shape files and metadata exported')
    # endregion


if __name__ == "__main__":
    main()
